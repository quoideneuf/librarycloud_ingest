<?xml version="1.0" encoding="UTF-8"?>
<beans xmlns="http://www.springframework.org/schema/beans"
    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xmlns:context="http://www.springframework.org/schema/context"
    xsi:schemaLocation="
    http://www.springframework.org/schema/beans 
    http://www.springframework.org/schema/beans/spring-beans.xsd
    http://camel.apache.org/schema/spring 
    http://camel.apache.org/schema/spring/camel-spring.xsd
    http://www.springframework.org/schema/context 
    http://www.springframework.org/schema/context/spring-context-3.0.xsd" 
    >
    
    <!-- AWS Configuration -->
    <context:property-placeholder  location="classpath:/aws.properties" />
    <bean name="sqsClient" class="com.amazonaws.services.sqs.AmazonSQSAsyncClient">
        <constructor-arg>
            <bean class="com.amazonaws.auth.BasicAWSCredentials">
                <constructor-arg value="${access.key}"/>
                <constructor-arg value="${secret.key}"/>
            </bean>
        </constructor-arg>
    </bean>

    <!-- Set a shorter timeout for shutdown, primarily for testing purposes. Default is 300. -->
    <bean id="shutdown" class="org.apache.camel.impl.DefaultShutdownStrategy">  
        <property name="timeout" value="30"/>
    </bean>  

    <!-- Configure display of trace log messages -->
    <bean id="traceFormatter" class="org.apache.camel.processor.interceptor.DefaultTraceFormatter">
        <property name="showBody" value="false"/>
        <property name="showHeaders" value="false"/>
    </bean>
    
    <!-- Add an event notifier to log throughput -->
    <!-- <bean id="eventTimer" class="edu.harvard.libcomm.pipeline.EventTimer"/> -->

    <!-- Definition of beans that handle processing of items in the pipeline -->
	<bean id="marcSplitter" class="edu.harvard.libcomm.pipeline.MarcSplitter"/>		
    <bean id="modsProcessor" class="edu.harvard.libcomm.pipeline.LibCommProcessor">
        <property name="processor">
            <bean class="edu.harvard.libcomm.pipeline.ModsProcessor"/>
        </property>
    </bean>
    <bean id="holdingsProcessor" class="edu.harvard.libcomm.pipeline.LibCommProcessor">
        <property name="processor">
            <bean class="edu.harvard.libcomm.pipeline.HoldingsProcessor"/>
        </property>
    </bean>

    <bean id="publishProcessor" class="edu.harvard.libcomm.pipeline.LibCommProcessor">
        <property name="processor">
            <bean class="edu.harvard.libcomm.pipeline.PublishProcessor"/>
        </property>
    </bean>

    <bean id="solrLoadProcessor" class="edu.harvard.libcomm.pipeline.LibCommProcessor">
        <property name="processor">
            <bean class="edu.harvard.libcomm.pipeline.SolrProcessor">
                <property name="commitWithinTime" value="30000"/>
            </bean>
        </property>
    </bean>

	<bean id="eadSplitter" class="edu.harvard.libcomm.pipeline.EADSplitter"/>

    <camelContext id="sqsContext" xmlns="http://camel.apache.org/schema/spring" trace="true">
        <!-- Environment-specific properties -->
        <propertyPlaceholder id="librarycloud-properties" location="classpath:/librarycloud.env.properties" />

        <!-- Error handling behavior -->
        <errorHandler id="eh" redeliveryPolicyRef="myPolicy" type="DeadLetterChannel" 
            deadLetterUri="direct:dead-letter"/>
        <redeliveryPolicyProfile id="myPolicy" maximumRedeliveries="0"/>

        <route id="dead-letter">
            <from uri="direct:dead-letter"/>
            <to uri="log:edu.harvard.libcomm.deadletterqueue?level=ERROR"/>
            <to uri="aws-sqs://{{librarycloud.sqs.environment}}-dead-letter?accessKey=${access.key}&amp;secretKey=${secret.key}&amp;amazonSQSClient=#sqsClient"/>
        </route>

 		<!-- 
 		aleph-ingest route reads xml messages from directory that contain corresponding marc (.mrc) files
 		converts marc communication format to marcxml, chunks into files of 25 and writes to specified directory
 		xml messages sent to queue
 		 -->
        <route id="aleph-ingest-split" errorHandlerRef="eh">
            <from uri="file:{{librarycloud.files.basepath}}/ingest-aleph?include=.*.xml" />

            <!-- Try block required for errors thrown out of the splitter -->
            <doTry>
                <split streaming="true" parallelProcessing="true">
                    <method bean="marcSplitter" method="splitMarcFile"/>
                    <to uri="aws-sqs://{{librarycloud.sqs.environment}}-normalize-marcxml?accessKey=${access.key}&amp;secretKey=${secret.key}&amp;amazonSQSClient=#sqsClient" />
                    <!-- <to uri="file://{{librarycloud.files.basepath}}/normalize-marcxml?fileName=${header.CamelSplitIndex}" /> -->
                </split>
                <doCatch>
                    <exception>java.lang.Exception</exception>
                    <to uri="direct:dead-letter" />
                </doCatch>
            </doTry>

         </route>

  		<!-- 
 		marctomods route reads marcxml from specified dir, validates, converts marcxml to mods
 		mods wrapped in libcomm message and sent to queue (can be file, aws, etc)
 		 -->         

        <!-- Pulling items from SQS to the Seda queue allows us to process multiple requests in parallel on multi-core servers -->
        <route id="marctomods-seda" errorHandlerRef="eh"> 
            <!-- <from uri="file://{{librarycloud.files.basepath}}/normalize-marcxml" /> -->
            <from uri="aws-sqs://{{librarycloud.sqs.environment}}-normalize-marcxml?accessKey=${access.key}&amp;secretKey=${secret.key}&amp;amazonSQSClient=#sqsClient&amp;maxMessagesPerPoll=10" />
            <to uri="seda:normalize-marcxml?size=20&amp;blockWhenFull=true"/>
        </route>

        <route id="marctomods"  errorHandlerRef="eh">
            <from uri="seda:normalize-marcxml?concurrentConsumers=4" />
            <process ref="modsProcessor"/>
            <to uri="aws-sqs://{{librarycloud.sqs.environment}}-enrich-start?accessKey=${access.key}&amp;secretKey=${secret.key}&amp;amazonSQSClient=#sqsClient" />
            <!-- <to uri="file://{{librarycloud.files.basepath}}/enrich-start" /> -->
        </route>
        
        <route id="addholdingstomods-seda" errorHandlerRef="eh">
            <!-- <from uri="file://{{librarycloud.files.basepath}}//enrich-start" /> -->
            <from uri="aws-sqs://{{librarycloud.sqs.environment}}-enrich-start?accessKey=${access.key}&amp;secretKey=${secret.key}&amp;amazonSQSClient=#sqsClient&amp;maxMessagesPerPoll=10" />
            <to uri="seda:addholdingstomods?size=20&amp;blockWhenFull=true" />
        </route>

		<route id="addholdingstomods" errorHandlerRef="eh">
            <from uri="seda:addholdingstomods?concurrentConsumers=1"/>
            <process ref="holdingsProcessor"/>
            <to uri="aws-sqs://{{librarycloud.sqs.environment}}-enrich-end?accessKey=${access.key}&amp;secretKey=${secret.key}&amp;amazonSQSClient=#sqsClient" />
            <!-- <to uri="file://{{librarycloud.files.basepath}}/enrich-end" /> -->
        </route>

        <route id="publish-seda" errorHandlerRef="eh">
            <!-- <from uri="file://{{librarycloud.files.basepath}}/enrich-end" /> -->
            <from uri="aws-sqs://{{librarycloud.sqs.environment}}-enrich-end?accessKey=${access.key}&amp;secretKey=${secret.key}&amp;amazonSQSClient=#sqsClient&amp;maxMessagesPerPoll=10" />
            <to uri="seda:enrich-end?size=20&amp;blockWhenFull=true"/>
        </route>

		<route id="publish" errorHandlerRef="eh">
            <from uri="seda:enrich-end?concurrentConsumers=1" />
            <process ref="publishProcessor"/>
            <to uri="aws-sqs://{{librarycloud.sqs.environment}}-publish-public?accessKey=${access.key}&amp;secretKey=${secret.key}&amp;amazonSQSClient=#sqsClient" />
            <!-- <to uri="file://{{librarycloud.files.basepath}}/publish-public" /> -->
        </route>

        <route id="modstosolr-seda" errorHandlerRef="eh">
            <!-- <from uri="file://{{librarycloud.files.basepath}}/publish-public" /> -->
            <from uri="aws-sqs://{{librarycloud.sqs.environment}}-publish-public?accessKey=${access.key}&amp;secretKey=${secret.key}&amp;amazonSQSClient=#sqsClient&amp;maxMessagesPerPoll=10" />
            <to uri="seda:publish-public?size=20&amp;blockWhenFull=true"/>
        </route>

		<route id="modstosolr" errorHandlerRef="eh">
            <from uri="seda:publish-public?concurrentConsumers=1" />
            <process ref="solrLoadProcessor"/>
            <to uri="log:edu.harvard.libcomm.throughput?level=TRACE&amp;marker=solrLoadProcessor&amp;groupSize=10"/>
            <to uri="aws-sqs://{{librarycloud.sqs.environment}}-done?accessKey=${access.key}&amp;secretKey=${secret.key}&amp;amazonSQSClient=#sqsClient"/>
            <!-- <to uri="file://{{librarycloud.files.basepath}}/done" /> -->
        </route>

		<!--  begin oasis routes -->
        <route id="oasis-ingest">
            <from uri="file:{{librarycloud.files.basepath}}/oasis?include=.*.xml" />
            <split streaming="true">
                <method bean="eadSplitter" method="splitEADFiles"/>
                <to uri="file:{{librarycloud.files.basepath}}/publish?fileName=${header.CamelSplitIndex}"/>
                <!-- <to uri="aws-sqs://{{librarycloud.sqs.environment}}-normalize-marcxml?accessKey=${access.key}&amp;secretKey=${secret.key}&amp;amazonSQSClient=#sqsClient" />-->
            </split>
         </route>
              
    </camelContext>
    
    
</beans>

<?xml version="1.0" encoding="UTF-8"?>
<beans xmlns="http://www.springframework.org/schema/beans"
    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xmlns:context="http://www.springframework.org/schema/context"
    xsi:schemaLocation="
    http://www.springframework.org/schema/beans
    http://www.springframework.org/schema/beans/spring-beans.xsd
    http://camel.apache.org/schema/spring
    http://camel.apache.org/schema/spring/camel-spring.xsd
    http://www.springframework.org/schema/context
    http://www.springframework.org/schema/context/spring-context-3.0.xsd"
    >
    <!-- AWS Configuration -->
    <context:property-placeholder location="classpath:/aws.properties" />
    <bean name="sqsClient" class="com.amazonaws.services.sqs.AmazonSQSAsyncClient">
        <constructor-arg>
            <bean class="com.amazonaws.auth.BasicAWSCredentials">
                <constructor-arg value="${access.key}"/>
                <constructor-arg value="${secret.key}"/>
            </bean>
        </constructor-arg>
    </bean>
    <!-- Set a shorter timeout for shutdown, primarily for testing purposes. Default is 300. -->
    <bean id="shutdown" class="org.apache.camel.impl.DefaultShutdownStrategy">
        <property name="timeout" value="30"/>
    </bean>
    <!-- Configure display of trace log messages -->
    <bean id="traceFormatter" class="org.apache.camel.processor.interceptor.DefaultTraceFormatter">
        <property name="showBody" value="false"/>
        <property name="showHeaders" value="false"/>
    </bean>
    <!-- Add an event notifier to log throughput -->
    <!-- <bean id="eventTimer" class="edu.harvard.libcomm.pipeline.EventTimer"/> -->
    <!-- Definition of beans that handle processing of items in the pipeline -->
    <bean id="marcSplitter" class="edu.harvard.libcomm.pipeline.Splitter">
        <property name="splitter">
            <bean class="edu.harvard.libcomm.pipeline.MarcSplitter"/>
        </property>
    </bean>
    <bean id="eadSplitter" class="edu.harvard.libcomm.pipeline.Splitter">
        <property name="splitter">
            <bean class="edu.harvard.libcomm.pipeline.EADSplitter"/>
        </property>
    </bean>
    <bean id="viaSplitter" class="edu.harvard.libcomm.pipeline.Splitter">
        <property name="splitter">
            <bean class="edu.harvard.libcomm.pipeline.VIASplitter"/>
        </property>
    </bean>
    <bean id="modsProcessor" class="edu.harvard.libcomm.pipeline.LibCommProcessor">
        <property name="processor">
            <bean class="edu.harvard.libcomm.pipeline.ModsProcessor"/>
        </property>
    </bean>
    <bean id="holdingsProcessor" class="edu.harvard.libcomm.pipeline.LibCommProcessor">
        <property name="processor">
            <bean class="edu.harvard.libcomm.pipeline.HoldingsProcessor"/>
        </property>
    </bean>
    <bean id="stackscoreProcessor" class="edu.harvard.libcomm.pipeline.LibCommProcessor">
        <property name="processor">
            <bean class="edu.harvard.libcomm.pipeline.StackScoreProcessor"/>
        </property>
    </bean>
    <bean id="collectionsProcessor" class="edu.harvard.libcomm.pipeline.LibCommProcessor">
        <property name="processor">
            <bean class="edu.harvard.libcomm.pipeline.CollectionsProcessor"/>
        </property>
    </bean>
    <bean id="publishProcessor" class="edu.harvard.libcomm.pipeline.LibCommProcessor">
        <property name="processor">
            <bean class="edu.harvard.libcomm.pipeline.PublishProcessor"/>
        </property>
    </bean>
    <bean id="solrLoadProcessor" class="edu.harvard.libcomm.pipeline.LibCommProcessor">
        <property name="processor">
            <bean class="edu.harvard.libcomm.pipeline.SolrProcessor">
                <property name="commitWithinTime" value="30000"/>
            </bean>
        </property>
    </bean>
    <camelContext id="sqsContext" xmlns="http://camel.apache.org/schema/spring" trace="true">
        <!-- Environment-specific properties -->
        <propertyPlaceholder id="librarycloud-properties" location="classpath:/librarycloud.env.properties" />
        <!-- Error handling behavior -->
        <errorHandler id="eh" redeliveryPolicyRef="myPolicy" type="DeadLetterChannel"
            deadLetterUri="direct:dead-letter"/>
        <redeliveryPolicyProfile id="myPolicy" maximumRedeliveries="0"/>
        <route id="dead-letter">
            <from uri="direct:dead-letter"/>
            <to uri="log:edu.harvard.libcomm.deadletterqueue?level=ERROR"/>
            <!-- Post to the AWS dead letter queue, and handle errors (e.g. file size exceeded) -->
            <doTry>
                <to uri="aws-sqs://{{librarycloud.sqs.environment}}-dead-letter?accessKey=${access.key}&amp;secretKey=${secret.key}&amp;amazonSQSClient=#sqsClient"/>
                <doCatch>
                    <!-- If can't post the full message to the dead letter queue, post only the headers to the queue -->
                    <exception>java.lang.Exception</exception>
                    <to uri="log:edu.harvard.libcomm.deadletterqueue?level=ERROR&amp;showAll=true"/>
                    <transform>
                        <simple>Error placing failed message on dead letter queue. Headers for affected message: ${headers}</simple>
                    </transform>
                    <doTry>
                        <to uri="aws-sqs://{{librarycloud.sqs.environment}}-dead-letter?accessKey=${access.key}&amp;secretKey=${secret.key}&amp;amazonSQSClient=#sqsClient"/>
                        <doCatch>
                            <!-- If can't even post the headers to the dead letter queue, log error and be done -->
                            <exception>java.lang.Exception</exception>
                            <transform>
                                <simple>Error placing failed message headers on dead letter queue. Headers for affected message: ${headers}</simple>
                            </transform>
                            <to uri="log:edu.harvard.libcomm.deadletterqueue?level=ERROR&amp;showAll=true"/>
                        </doCatch>
                    </doTry>
                </doCatch>
            </doTry>
        </route>
        <!-- Aleph ingest and normalization -->
        <route id="aleph-ingest-split" errorHandlerRef="eh">
            <!-- <from uri="file:{{librarycloud.files.basepath}}/ingest-aleph?include=.*.xml" /> -->
            <from uri="aws-sqs://{{librarycloud.sqs.environment}}-ingest-aleph?accessKey=${access.key}&amp;secretKey=${secret.key}&amp;amazonSQSClient=#sqsClient&amp;visibilityTimeout=1800" />
            <!-- Try block required for errors thrown out of the splitter -->
            <doTry>
                <split streaming="true" parallelProcessing="true">
                    <method bean="marcSplitter" method="split"/>
                    <to uri="aws-sqs://{{librarycloud.sqs.environment}}-normalize-marcxml?accessKey=${access.key}&amp;secretKey=${secret.key}&amp;amazonSQSClient=#sqsClient" />
                    <!-- <to uri="file://{{librarycloud.files.basepath}}/normalize-marcxml?fileName=${header.CamelSplitIndex}" /> -->
                </split>
                <doCatch>
                    <exception>java.lang.Exception</exception>
                    <to uri="direct:dead-letter" />
                </doCatch>
            </doTry>
        </route>
        <!-- Pulling items from SQS to the Seda queue allows us to process multiple requests in parallel on multi-core servers -->
        <route id="marctomods-seda" errorHandlerRef="eh">
            <!-- <from uri="file://{{librarycloud.files.basepath}}/normalize-marcxml" /> -->
            <from uri="aws-sqs://{{librarycloud.sqs.environment}}-normalize-marcxml?accessKey=${access.key}&amp;secretKey=${secret.key}&amp;amazonSQSClient=#sqsClient&amp;maxMessagesPerPoll=10" />
            <to uri="seda:normalize-marcxml?size=20&amp;blockWhenFull=true"/>
        </route>
        <route id="marctomods" errorHandlerRef="eh">
            <from uri="seda:normalize-marcxml?concurrentConsumers=4" />
            <process ref="modsProcessor"/>
            <to uri="aws-sqs://{{librarycloud.sqs.environment}}-enrich-start?accessKey=${access.key}&amp;secretKey=${secret.key}&amp;amazonSQSClient=#sqsClient" />
            <!-- <to uri="file://{{librarycloud.files.basepath}}/enrich-start" /> -->
        </route>
        <route id="addholdingstomods-seda" errorHandlerRef="eh">
            <!-- <from uri="file://{{librarycloud.files.basepath}}//enrich-start" /> -->
            <from uri="aws-sqs://{{librarycloud.sqs.environment}}-enrich-start?accessKey=${access.key}&amp;secretKey=${secret.key}&amp;amazonSQSClient=#sqsClient&amp;maxMessagesPerPoll=10" />
            <to uri="seda:addholdingstomods?size=20&amp;blockWhenFull=true" />
        </route>
        <route id="addholdingstomods" errorHandlerRef="eh">
            <from uri="seda:addholdingstomods?concurrentConsumers=1"/>
            <process ref="holdingsProcessor"/>
            <to uri="aws-sqs://{{librarycloud.sqs.environment}}-enrich-02?accessKey=${access.key}&amp;secretKey=${secret.key}&amp;amazonSQSClient=#sqsClient" />
            <!-- <to uri="file://{{librarycloud.files.basepath}}/enrich-02" /> -->
        </route>
        <route id="addstackscoretomods-seda" errorHandlerRef="eh">
            <!-- <from uri="file://{{librarycloud.files.basepath}}//enrich-02" /> -->
            <from uri="aws-sqs://{{librarycloud.sqs.environment}}-enrich-02?accessKey=${access.key}&amp;secretKey=${secret.key}&amp;amazonSQSClient=#sqsClient&amp;maxMessagesPerPoll=10" />
            <to uri="seda:addstackscoretomods?size=20&amp;blockWhenFull=true" />
        </route>
        <route id="addstackscoretomods" errorHandlerRef="eh">
            <from uri="seda:addstackscoretomods?concurrentConsumers=1"/>
            <process ref="stackscoreProcessor"/>
            <to uri="aws-sqs://{{librarycloud.sqs.environment}}-enrich-03?accessKey=${access.key}&amp;secretKey=${secret.key}&amp;amazonSQSClient=#sqsClient" />
            <!-- <to uri="file://{{librarycloud.files.basepath}}/enrich-03" /> -->
        </route>
        <route id="addcollectionstomods-seda" errorHandlerRef="eh">
            <!-- <from uri="file://{{librarycloud.files.basepath}}//enrich-03" /> -->
            <from uri="aws-sqs://{{librarycloud.sqs.environment}}-enrich-03?accessKey=${access.key}&amp;secretKey=${secret.key}&amp;amazonSQSClient=#sqsClient&amp;maxMessagesPerPoll=10" />
            <to uri="seda:addcollectionstomods?size=20&amp;blockWhenFull=true" />
        </route>
        <route id="addcollectionstomods" errorHandlerRef="eh">
            <from uri="seda:addcollectionstomods?concurrentConsumers=1"/>
            <process ref="collectionsProcessor"/>
            <to uri="aws-sqs://{{librarycloud.sqs.environment}}-enrich-end?accessKey=${access.key}&amp;secretKey=${secret.key}&amp;amazonSQSClient=#sqsClient" />
            <!-- <to uri="file://{{librarycloud.files.basepath}}/enrich-end" /> -->
        </route>
        <!-- Publishing records to consumers -->
        <route id="publish-seda" errorHandlerRef="eh">
            <!-- <from uri="file://{{librarycloud.files.basepath}}/enrich-end" /> -->
            <from uri="aws-sqs://{{librarycloud.sqs.environment}}-enrich-end?accessKey=${access.key}&amp;secretKey=${secret.key}&amp;amazonSQSClient=#sqsClient&amp;maxMessagesPerPoll=10" />
            <to uri="seda:enrich-end?size=20&amp;blockWhenFull=true"/>
        </route>
        <route id="publish" errorHandlerRef="eh">
            <from uri="seda:enrich-end?concurrentConsumers=1" />
            <process ref="publishProcessor"/>
            <to uri="aws-sqs://{{librarycloud.sqs.environment}}-publish-public?accessKey=${access.key}&amp;secretKey=${secret.key}&amp;amazonSQSClient=#sqsClient" />
            <!-- <to uri="file://{{librarycloud.files.basepath}}/publish-public" /> -->
        </route>
        <!-- OASIS ingest and normalization -->
        <route id="oasis-ingest-seda" errorHandlerRef="eh">
            <!-- <from uri="file://{{librarycloud.files.basepath}}/ingest-oasis" /> -->
            <from uri="aws-sqs://{{librarycloud.sqs.environment}}-ingest-oasis?accessKey=${access.key}&amp;secretKey=${secret.key}&amp;amazonSQSClient=#sqsClient&amp;visibilityTimeout=1800" />
            <to uri="seda:oasis-ingest-seda?size=10&amp;blockWhenFull=true"/>
        </route>
        <route id="oasis-ingest" errorHandlerRef="eh">
            <from uri="seda:oasis-ingest-seda?concurrentConsumers=4" />
            <!-- Try block required for errors thrown out of the splitter -->
            <doTry>
                <split streaming="true" parallelProcessing="true">
                    <method bean="eadSplitter" method="split"/>
                    <to uri="aws-sqs://{{librarycloud.sqs.environment}}-publish-public?accessKey=${access.key}&amp;secretKey=${secret.key}&amp;amazonSQSClient=#sqsClient" />
                    <!-- <to uri="file://{{librarycloud.files.basepath}}/publish-public?fileName=${header.CamelSplitIndex}" /> -->
                </split>
                <doCatch>
                    <exception>java.lang.Exception</exception>
                    <to uri="direct:dead-letter" />
                </doCatch>
            </doTry>
        </route>
        <!-- VIA ingest and normalization -->
        <route id="via-ingest-seda" errorHandlerRef="eh">
            <from uri="file://{{librarycloud.files.basepath}}/ingest-via" />
            <!-- <from uri="aws-sqs://{{librarycloud.sqs.environment}}-ingest-via?accessKey=${access.key}&amp;secretKey=${secret.key}&amp;amazonSQSClient=#sqsClient&amp;visibilityTimeout=1800" /> -->
            <to uri="seda:via-ingest-seda?size=10&amp;blockWhenFull=true"/>
        </route>
        <route id="via-ingest" errorHandlerRef="eh">
            <from uri="seda:via-ingest-seda?concurrentConsumers=4" />
            <!-- Try block required for errors thrown out of the splitter -->
            <doTry>
                <split streaming="true" parallelProcessing="true">
                    <method bean="viaSplitter" method="split"/>
                    <!-- <to uri="aws-sqs://{{librarycloud.sqs.environment}}-publish-public?accessKey=${access.key}&amp;secretKey=${secret.key}&amp;amazonSQSClient=#sqsClient" /> -->
                    <to uri="file://{{librarycloud.files.basepath}}/publish-public?fileName=${header.CamelSplitIndex}" />
                </split>
                <doCatch>
                    <exception>java.lang.Exception</exception>
                    <to uri="direct:dead-letter" />
                </doCatch>
            </doTry>
        </route>
        <!-- SOLR consumer for loading into item API -->
        <route id="modstosolr-seda" errorHandlerRef="eh">
            <!-- <from uri="file://{{librarycloud.files.basepath}}/publish-public" /> -->
            <from uri="aws-sqs://{{librarycloud.sqs.environment}}-publish-public?accessKey=${access.key}&amp;secretKey=${secret.key}&amp;amazonSQSClient=#sqsClient&amp;maxMessagesPerPoll=10" />
            <to uri="seda:publish-public?size=20&amp;blockWhenFull=true"/>
        </route>
        <route id="modstosolr" errorHandlerRef="eh">
            <from uri="seda:publish-public?concurrentConsumers=1" />
            <process ref="solrLoadProcessor"/>
            <to uri="log:edu.harvard.libcomm.throughput?level=TRACE&amp;marker=solrLoadProcessor&amp;groupSize=10"/>
            <to uri="aws-sqs://{{librarycloud.sqs.environment}}-done?accessKey=${access.key}&amp;secretKey=${secret.key}&amp;amazonSQSClient=#sqsClient"/>
            <!-- <to uri="file://{{librarycloud.files.basepath}}/done" /> -->
        </route>
    </camelContext>
</beans>